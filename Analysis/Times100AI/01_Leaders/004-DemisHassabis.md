# Demis Hassabis

## Credentials

Google DeepMind - organized information, god-eye view

## Knowing The Person

building powerful artificial intelligence

## Topics

**multi-model** Gemini
Path towards AGI - scientific advancement, shape world for better (AI powered products)
**unitary piece of information** - Facts/Models of the Real World
Sparrow (**Safer Dialogue Agent**) - Preferred Response/Adversarial Probing [https://www.deepmind.com/blog/building-safer-dialogue-agents]
**Evaluation Benchmarks**
**The Frontier Model Forum** - [https://blogs.microsoft.com/on-the-issues/2023/07/26/anthropic-google-microsoft-openai-launch-frontier-model-forum/] 

## Analysis

I personally think that setting Evaluation Benchmarks is the way to go if at all possible, as other researchers are willing to replicate and meet benchmarks. The way to do so, from my intuition is to write a paper or design a class that easily onboard people into the research. They will carry the benchmark forwards as they are taught with it in mind.

I'm personally skeptical of AI researchers wanting to play governing boards with the "Frontier Model Forum" but I can see it as something potentially being super important as AI actually becomes powerful on the world stage