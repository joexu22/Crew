Verity Harding
Director of the AI & Geopolitics Project, Cambridge University

Few people understand the intersection between emerging technology and democracy better than Verity Harding. The British politico turned AI expert has spent more than a decade focusing on transformative technologies and the impact they stand to have on democratic societies, first as a special adviser to former British Deputy Prime Minister Nick Clegg (working on issues around digital privacy) and then at Google and ultimately DeepMind, one of the world’s leading AI labs, where she co-founded its research and ethics unit and took the lead on global policy.

The move from Westminster to tech was an effort to be more effective, she says. “​​There was just this huge democratic deficit in terms of what elected representatives of the people knew and understood about it vs. what the tech companies knew vs. what the security services knew,” Harding tells TIME. Now, she is leading a wider campaign to pursue a “rights-based approach” to AI governance that includes not just the people building AI, but also those who stand to be most impacted by it. She currently serves as the founder of the consultancy Formation Advisory and as the director of the AI & Geopolitics Project at Cambridge University, which aims to provide an alternative to the “AI-arms-race” narrative by encouraging global cooperation and creating new frameworks that place human rights and democracy at the heart of tech policy.

“AI is too important just to be left to the AI community alone,” Harding says. “It needs to be more widespread.”

Harding believes it’s crucial to avoid purely top-down regulation and that a more collaborative and global approach is possible. That’s partly because it has been done before. In her forthcoming book AI Needs You: How We Can Change AI’s Future and Save Our Own, Harding points to three earlier tech revolutions—the space race, IVF and embryology research, and the internet―and the lessons they offer for dealing with emerging and uncertain technology at a global level. Just as the world was able to reach a consensus with the U.N. Outer Space Treaty of 1967, which forms the basis of international space law to this day, Harding hopes that similar multilateral efforts will be achieved in the realm of AI, current geopolitical tensions between the U.S. and China notwithstanding.

“At the moment, AI and geopolitics is purely seen as an issue of national security, state power, a tool to be wielded and kind of a contest to be won instead of potential for collaboration and a potential for human advancement and a potential for a rights-based approach to advanced technologies,” Harding says. “I think we have just kind of accepted the AI-arms-race narrative, but I don’t think it’s a helpful or safe one.”

## Credentials